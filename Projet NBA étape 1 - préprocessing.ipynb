{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd85b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad75a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 100209: expected 34 fields, saw 57\\n'\n",
      "b'Skipping line 501558: expected 34 fields, saw 47\\n'\n",
      "b'Skipping line 601798: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 802080: expected 34 fields, saw 39\\n'\n",
      "b'Skipping line 1002194: expected 34 fields, saw 51\\n'\n",
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_11792\\3939092654.py:26: DtypeWarning: Columns (3,6,8,10,12,16,18,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df15_16 = pd.read_csv('2015-16_pbp.csv', on_bad_lines='warn')\n",
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_11792\\3939092654.py:36: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df5 = pd.read_csv('games_details.csv')\n"
     ]
    }
   ],
   "source": [
    "# ouverture des différents datasets\n",
    "\n",
    "#dataset1\n",
    "os.chdir(\"C:/Users/antho/Projet_NBA/Dataset1_Tirs de NBA entre 1997 et 2019\")\n",
    "df1 = pd.read_csv('NBA Shot Locations 1997 - 2020.csv')\n",
    "\n",
    "#dataset2\n",
    "os.chdir(\"C:/Users/antho/Projet_NBA/Dataset2_Actions de chaque match entre 2000 et 2020\")\n",
    "\n",
    "# ouverture des 19 fichiers, un par saison, un fichier 2015-16 comporte 5 lignes à problèmes que j'ai supprimé\n",
    "df00_01 = pd.read_csv('2000-01_pbp.csv')\n",
    "df01_02 = pd.read_csv('2001-02_pbp.csv')\n",
    "df02_03 = pd.read_csv('2002-03_pbp.csv')\n",
    "df03_04 = pd.read_csv('2003-04_pbp.csv')\n",
    "df04_05 = pd.read_csv('2004-05_pbp.csv')\n",
    "df05_06 = pd.read_csv('2005-06_pbp.csv')\n",
    "df06_07 = pd.read_csv('2006-07_pbp.csv')\n",
    "df07_08 = pd.read_csv('2007-08_pbp.csv')\n",
    "df08_09 = pd.read_csv('2008-09_pbp.csv')\n",
    "df09_10 = pd.read_csv('2009-10_pbp.csv')\n",
    "df10_11 = pd.read_csv('2010-11_pbp.csv')\n",
    "df11_12 = pd.read_csv('2011-12_pbp.csv')\n",
    "df12_13 = pd.read_csv('2012-13_pbp.csv')\n",
    "df13_14 = pd.read_csv('2013-14_pbp.csv')\n",
    "df14_15 = pd.read_csv('2014-15_pbp.csv')\n",
    "df15_16 = pd.read_csv('2015-16_pbp.csv', on_bad_lines='warn')\n",
    "df16_17 = pd.read_csv('2016-17_pbp.csv')\n",
    "df17_18 = pd.read_csv('2017-18_pbp.csv')\n",
    "df18_19 = pd.read_csv('2018-19_pbp.csv')\n",
    "# le fichier df19_20 est inexploitable car structure différente\n",
    "\n",
    "\n",
    "#dataset3\n",
    "os.chdir(\"C:/Users/antho/Projet_NBA/Dataset3_Bilans d'équipe entre 2014 et 2018\")\n",
    "df4 = pd.read_csv('games.csv')\n",
    "df5 = pd.read_csv('games_details.csv')\n",
    "df6 = pd.read_csv('teams.csv')\n",
    "df7 = pd.read_csv('players.csv')\n",
    "df8 = pd.read_csv('ranking.csv')\n",
    "\n",
    "#dataset4\n",
    "os.chdir(\"C:/Users/antho/Projet_NBA/Dataset4_Joueurs de NBA depuis 1950\")\n",
    "df9 = pd.read_csv('player_data.xls')\n",
    "df10 = pd.read_csv('Players.xls')\n",
    "df11 = pd.read_csv('Seasons_Stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ea428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.loc[(df1['Player Name'] == 'Tim Duncan') | (df1['Player Name'] == 'Kobe Bryant') | (df1['Player Name'] == 'Allen Iverson')\n",
    "              | (df1['Player Name'] == 'Steve Nash') | (df1['Player Name'] == 'Ray Allen') | (df1['Player Name'] == 'Paul Pierce')\n",
    "              | (df1['Player Name'] == 'Pau Gasol') | (df1['Player Name'] == 'Tony Parker') | (df1['Player Name'] == 'Manu Ginobili')\n",
    "              | (df1['Player Name'] == 'Dwyane Wade') | (df1['Player Name'] == 'LeBron James') | (df1['Player Name'] == 'Chris Paul')\n",
    "              | (df1['Player Name'] == 'Kevin Durant') | (df1['Player Name'] == 'Russell Westbrook') | (df1['Player Name'] == 'Stephen Curry')\n",
    "              | (df1['Player Name'] == 'James Harden') | (df1['Player Name'] == 'Kawhi Leonard') | (df1['Player Name'] == 'Damian Lillard')\n",
    "              | (df1['Player Name'] == 'Anthony Davis') | (df1['Player Name'] == 'Giannis Antetokounmpo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13f3778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_11792\\2179496741.py:15: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df20 = df8.groupby(['TEAM_ID','SEASON_ID'])['G','W','L'].max().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# transformer la variable SEASON_ID entier en objet afin de pouvoir faire l'étape suivante\n",
    "df8['SEASON_ID'] = df8['SEASON_ID'].apply(str)\n",
    "\n",
    "# SEASON_ID : 12020 ou 22020, on enlève le premier élément de la chaine de caractère\n",
    "df8['SEASON_ID'] = df8['SEASON_ID'].apply(lambda saison: saison[1:])\n",
    "\n",
    "# je supprime les colonnes qui ne nous intéressent pas\n",
    "df8 = df8.drop(['LEAGUE_ID','STANDINGSDATE','TEAM','HOME_RECORD','ROAD_RECORD','RETURNTOPLAY'],axis = 1)\n",
    "\n",
    "# je supprime les doublons et ne garde que la première ligne\n",
    "df8 = df8.drop_duplicates(keep = 'first')\n",
    "\n",
    "# je regroupe le df8 par équipe et par saison et garde pour chaque équipe par saison la valeur max de G(Game), W(victoire) et \n",
    "# L (défaite), les 3 ensemble correspondent au dernière stat de la saison, au classement final (ce que l'on veut)\n",
    "df20 = df8.groupby(['TEAM_ID','SEASON_ID'])['G','W','L'].max().reset_index()\n",
    "\n",
    "# grâce aux 5 valeurs de df20, je viens rajouter la valeur 'W_PCT' correspondante\n",
    "df20 = df20.merge(right = df8,on = ['SEASON_ID','TEAM_ID','G','W','L'], how = 'inner')\n",
    "\n",
    "# je supprime les doublons si il y a\n",
    "df20 = df20.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae936f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20 = df20.drop([378,459,599])                                                                     \n",
    "\n",
    "#df20 = df20.drop_duplicates() ne m'affichait aucun doublons alors qu'il y en avait, pas compris donc \n",
    "#je les ai enlevé manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7885736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classement des équipes par saison de 2002 à 2021 en fonction de la valeur de W_PCT\n",
    "\n",
    "# trier en fonction de la saison et de la valeur de W_PCT\n",
    "df20 = df20.sort_values(['SEASON_ID','W_PCT'])\n",
    "\n",
    "# pour chaque saison, je crée un df trier par ordre croissant et je viens faire le classement en départageant deux valeurs\n",
    "# par la méthode first (première valeur dans le tableau en premier\n",
    "\n",
    "df2002 = df20[df20['SEASON_ID'] == '2002'].reset_index()\n",
    "df2002['classement'] = df2002['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2003 = df20[df20['SEASON_ID'] == '2003'].reset_index()\n",
    "df2003['classement'] = df2003['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2004 = df20[df20['SEASON_ID'] == '2004'].reset_index()\n",
    "df2004['classement'] = df2004['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2005 = df20[df20['SEASON_ID'] == '2005'].reset_index()\n",
    "df2005['classement'] = df2005['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2006 = df20[df20['SEASON_ID'] == '2006'].reset_index()\n",
    "df2006['classement'] = df2006['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2007 = df20[df20['SEASON_ID'] == '2007'].reset_index()\n",
    "df2007['classement'] = df2007['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2008 = df20[df20['SEASON_ID'] == '2008'].reset_index()\n",
    "df2008['classement'] = df2008['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2009 = df20[df20['SEASON_ID'] == '2009'].reset_index()\n",
    "df2009['classement'] = df2009['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2010 = df20[df20['SEASON_ID'] == '2010'].reset_index()\n",
    "df2010['classement'] = df2010['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2011 = df20[df20['SEASON_ID'] == '2011'].reset_index()\n",
    "df2011['classement'] = df2011['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2012 = df20[df20['SEASON_ID'] == '2012'].reset_index()\n",
    "df2012['classement'] = df2012['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2013 = df20[df20['SEASON_ID'] == '2013'].reset_index()\n",
    "df2013['classement'] = df2013['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2014 = df20[df20['SEASON_ID'] == '2014'].reset_index()\n",
    "df2014['classement'] = df2014['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2015 = df20[df20['SEASON_ID'] == '2015'].reset_index()\n",
    "df2015['classement'] = df2015['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2016 = df20[df20['SEASON_ID'] == '2016'].reset_index()\n",
    "df2016['classement'] = df2016['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2017 = df20[df20['SEASON_ID'] == '2017'].reset_index()\n",
    "df2017['classement'] = df2017['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2018 = df20[df20['SEASON_ID'] == '2018'].reset_index()\n",
    "df2018['classement'] = df2018['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2019 = df20[df20['SEASON_ID'] == '2019'].reset_index()\n",
    "df2019['classement'] = df2019['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2020 = df20[df20['SEASON_ID'] == '2020'].reset_index()\n",
    "df2020['classement'] = df2020['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df2021 = df20[df20['SEASON_ID'] == '2021'].reset_index()\n",
    "df2021['classement'] = df2021['W_PCT'].rank(method = 'min', ascending = False)\n",
    "\n",
    "df20 = pd.concat([df2002,df2003,df2004,df2005,df2006,df2007,df2008,df2009,df2010,df2011,df2012,df2013,df2014,df2015,df2016,df2017,df2018,df2019,df2020,df2021])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0b4292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insérer une variable birth_date avec les dates de naissance de chacun des 20 joueurs\n",
    "\n",
    "# renommer la variable afin que le merge puisse se faire\n",
    "df9 = df9.rename({'name' : 'Player Name'}, axis = 1)\n",
    "\n",
    "# on récupère les data de nos joueurs d'intérêts uniquement\n",
    "birth_date = df9.loc[(df9['Player Name'] == 'Tim Duncan') | (df9['Player Name'] == 'Kobe Bryant') | (df9['Player Name'] == 'Allen Iverson')\n",
    "              | (df9['Player Name'] == 'Steve Nash') | (df9['Player Name'] == 'Ray Allen') | (df9['Player Name'] == 'Paul Pierce')\n",
    "              | (df9['Player Name'] == 'Pau Gasol') | (df9['Player Name'] == 'Tony Parker') | (df9['Player Name'] == 'Manu Ginobili')\n",
    "              | (df9['Player Name'] == 'Dwyane Wade') | (df9['Player Name'] == 'LeBron James') | (df9['Player Name'] == 'Chris Paul')\n",
    "              | (df9['Player Name'] == 'Kevin Durant') | (df9['Player Name'] == 'Russell Westbrook') | (df9['Player Name'] == 'Stephen Curry')\n",
    "              | (df9['Player Name'] == 'James Harden') | (df9['Player Name'] == 'Kawhi Leonard') | (df9['Player Name'] == 'Damian Lillard')\n",
    "              | (df9['Player Name'] == 'Anthony Davis') | (df9['Player Name'] == 'Giannis Antetokounmpo')]\n",
    "\n",
    "# on supprime les colonnes qui ne nous intéressent pas (sauf birth_date et le poste)\n",
    "birth_date = birth_date.drop(['year_start','year_end','height','weight','college'], axis = 1)\n",
    "\n",
    "# on rajoute les colonnes birth_date et position dans le df1 en fonction de nos joueurs\n",
    "df1 = df1.merge(right = birth_date,on = 'Player Name', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1b218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer le format birth_date pour qu'il soit exploitable pour calculer l'âge de chaque joueur en fonction du match\n",
    "\n",
    "#créer une variable pour ne garder que l'année, le mois et le jour\n",
    "df1['year_birth_date'] = df1['birth_date'].apply(lambda date: date.split(',')[1])\n",
    "df1['month_birth_date'] = df1['birth_date'].apply(lambda date: date.split()[0])\n",
    "df1['day_birth_date'] = df1['birth_date'].apply(lambda date: date.split(',')[0].split()[1])\n",
    "\n",
    "#on transforme les mois : January en 01 et ainsi de suite\n",
    "df1 = df1.replace({'January' : '01', 'February' : '02', 'March' : '03', 'April' : '04', 'May' : '05', 'June' : '06', 'July' : '07', 'August' : '08', 'September' : '09', 'October' : '10', 'November' : '11', 'December' : '12'})\n",
    "\n",
    "# on concatène l'année, le mois et le jour\n",
    "df1['date_birth_date'] = df1['year_birth_date'] + '-' + df1['month_birth_date'] + '-' + df1['day_birth_date']\n",
    "\n",
    "# on convertit en format datetime\n",
    "df1['date_birth_date'] = pd.to_datetime(df1['date_birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3b06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer le format Game Date pour qu'il soit exploitable pour calculer l'âge de chaque joueur en fonction du match\n",
    "\n",
    "# on convertir Game Date en objet afin de pouvoir effectuer les prochaines étapes\n",
    "df1['Game Date'] = df1['Game Date'].apply(str)\n",
    "\n",
    "#créer une variable pour ne garder que l'année, le mois et le jour\n",
    "df1['year_Game Date'] = df1['Game Date'].apply(lambda date: date[:4])\n",
    "df1['month_Game Date'] = df1['Game Date'].apply(lambda date: date[4:6])\n",
    "df1['day_Game Date'] = df1['Game Date'].apply(lambda date: date[6:])\n",
    "\n",
    "# on concatène l'année, le mois et le jour\n",
    "df1['date_Game Date'] = df1['year_Game Date'] + '-' + df1['month_Game Date'] + '-' + df1['day_Game Date']\n",
    "\n",
    "# on convertit en format datetime\n",
    "df1['date_Game Date'] = pd.to_datetime(df1['date_Game Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c46acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on calcule l'âge du joueur pour chaque match en arrondissant à l'année inférieure (logique)\n",
    "\n",
    "df1['age'] = ((df1['date_Game Date'] - df1['date_birth_date']).dt.days / 365.2425) . apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3267ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour avoir le classement de chaque équipe à la fin de chaque saison\n",
    "\n",
    "# on renomme la variable GAME_ID pour pouvoir utiliser la fonction merge après\n",
    "df4 = df4.rename({'GAME_ID' : 'Game ID'}, axis = 1)\n",
    "\n",
    "# on choisit uniquement les variables qui nous intéressent : Game ID et SEASON\n",
    "df4 = df4.iloc[:,[1,3,4,5]]\n",
    "\n",
    "# on merge la saison\n",
    "df1 = df1.merge(right = df4,on = 'Game ID', how = 'inner')\n",
    "df1['adversaire_ID'] = np.where(df1['HOME_TEAM_ID'] == df1['Team ID'],df1['VISITOR_TEAM_ID'],df1['HOME_TEAM_ID'])\n",
    "\n",
    "# puis on merge le W_PCT et le classement de l'équipe à la fin de la saison grâce à la variable SEASON\n",
    "df20['SEASON_ID'] = df20['SEASON_ID'].apply(int)\n",
    "df20 = df20.rename({'SEASON_ID' : 'SEASON', 'TEAM_ID' : 'adversaire_ID'}, axis = 1)\n",
    "df20 = df20.iloc[:,[1,2,7,8]]\n",
    "\n",
    "df1 = df1.merge(right = df20,on = ['SEASON','adversaire_ID'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c928c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# certaines équipes ont changé de noms donc on remplace les anciens par le plus récent\n",
    "df1['Home Team'] = df1['Home Team'].replace({'VAN' : 'MEM', 'SEA' : 'OKC', 'NJN' : 'BKN', 'NOH' : 'NOP', 'NOK' : 'NOP', 'CHH' \n",
    "                                            : 'CHA'})\n",
    "df1['Away Team'] = df1['Away Team'].replace({'VAN' : 'MEM', 'SEA' : 'OKC', 'NJN' : 'BKN', 'NOH' : 'NOP', 'NOK' : 'NOP', 'CHH' \n",
    "                                            : 'CHA'})\n",
    "\n",
    "df5['TEAM_ABBREVIATION'] = df5['TEAM_ABBREVIATION'].replace({'VAN' : 'MEM', 'SEA' : 'OKC', 'NJN' : 'BKN', 'NOH' : 'NOP', 'NOK' \n",
    "                                                            : 'NOP', 'CHH' : 'CHA'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9dc6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insérer la variable TEAM_ABBREVIATION du df5 dans df1\n",
    "df5 = df5.iloc[:,[0,1,2]]\n",
    "df8 = df8.iloc[:,[0,2]]\n",
    "\n",
    "df21 = df8.groupby('TEAM_ID').max()\n",
    "df21 = df21.merge(right = df5, on = 'TEAM_ID', how = 'inner')\n",
    "\n",
    "df22 = df21.iloc[:,[0,3]]\n",
    "df22 = df22.rename({'TEAM_ID' : 'Team ID'}, axis = 1)\n",
    "df22 = df22.groupby('Team ID').max()\n",
    "df1 = df1.merge(right = df22, on = 'Team ID', how = 'inner')\n",
    "\n",
    "# joue à domicile (=1) ou à l'extérieur (=0)\n",
    "\n",
    "df1['domicile'] = np.where(df1['Home Team'] == df1['TEAM_ABBREVIATION'],1,0)\n",
    "\n",
    "# donner le nom de l'équipe adverse sous forme abbrégée\n",
    "df1['adversaire'] = np.where(df1['domicile'] == 1,df1['Away Team'],df1['Home Team'])\n",
    "\n",
    "# insérer la variable conférence_adversaire du df8 au df1\n",
    "conf = df21.iloc[:,[1,3]]\n",
    "conf = conf.rename({'TEAM_ABBREVIATION' : 'adversaire', 'CONFERENCE' : 'CONFERENCE_ADVERSAIRE'}, axis = 1)\n",
    "conf = conf.groupby('adversaire').max().reset_index()\n",
    "df1 = df1.merge(right = conf, on = 'adversaire', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f257a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle du shoot \n",
    "\n",
    "#calcul de l'angle A : A = arctan(X/Y)\n",
    "\n",
    "X_Y = df1['X Location'] / df1['Y Location']\n",
    "\n",
    "# des NaN ont été créé (0/0 : le joueur se situait au niveau du panier : dunk donc on peut estimer qu'il n'y a pas de \n",
    "# contrainte d'angle, comme si l'angle était de 0 peu importe où le joueur dunkait), les remplacer par la valeur 0 \n",
    "X_Y = X_Y.fillna(value = 0)\n",
    "\n",
    "# calcul de l'angle avec np.arctan\n",
    "df1['angle_tir'] = np.arctan(X_Y)\n",
    "\n",
    "# convertir la mesure (radian) en degré\n",
    "df1['angle_tir'] = ((df1['angle_tir'] * 180) / np.pi)\n",
    "\n",
    "#prendre la valeur absolue de l'angle\n",
    "df1['angle_tir'] = df1['angle_tir'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23850bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténer les variables minutes et secondes restantes pour en faire qu'une seule\n",
    "\n",
    "df1['Tps_restant'] = np.where(df1['Seconds Remaining'] < 10, df1['Minutes Remaining'].apply(str) + ':0' + df1['Seconds Remaining'].apply(str),\n",
    "         df1['Minutes Remaining'].apply(str) + ':' + df1['Seconds Remaining'].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc407bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement du dataset 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4815b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on garde uniquement les variables d'intérêts\n",
    "\n",
    "df00_01 = df00_01.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df01_02 = df01_02.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df02_03 = df02_03.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df03_04 = df03_04.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df04_05 = df04_05.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df05_06 = df05_06.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df06_07 = df06_07.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df07_08 = df07_08.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df08_09 = df08_09.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df09_10 = df09_10.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df10_11 = df10_11.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df11_12 = df11_12.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df12_13 = df12_13.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df13_14 = df13_14.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df14_15 = df14_15.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df15_16 = df15_16.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df16_17 = df16_17.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df17_18 = df17_18.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]\n",
    "df18_19 = df18_19.iloc[:,[2,3,4,5,7,8,12,13,14,16,19,25,30,31,32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f494c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on concatène tous les fichiers de 2000 à 2019\n",
    "\n",
    "df00_19 = pd.concat([df00_01,df01_02,df02_03,df03_04,df04_05,df05_06,df06_07,df07_08,df08_09,df09_10,df10_11,df11_12,df12_13,\n",
    "                     df13_14,df14_15,df15_16,df16_17,df17_18,df18_19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d8e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df00_19.drop(df00_19[df00_19['PCTIMESTRING'] == 'ATL'].index, inplace = True)\n",
    "df00_19 = df00_19.dropna(subset = ['PCTIMESTRING'], how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7582b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs NaN par 0 - 0 (SCOREMARGIN) et par 0 (SCORE) lors du début d'un match\n",
    "\n",
    "df00_19['SCOREMARGIN'] = np.where((df00_19['PCTIMESTRING'] == '12:00') & (df00_19['PERIOD'] == 1),0,df00_19['SCOREMARGIN'])\n",
    "df00_19['SCORE'] = np.where((df00_19['PCTIMESTRING'] == '12:00') & (df00_19['PERIOD'] == 1),'0 - 0',df00_19['SCORE'])\n",
    "df00_19['SCOREMARGIN'] = df00_19['SCOREMARGIN'].replace('TIE',0)\n",
    "\n",
    "# on remplacer les autres NaN par la précédente valeur (méthode ffill)\n",
    "df00_19['SCOREMARGIN'] = df00_19['SCOREMARGIN'].fillna(method = 'ffill')\n",
    "df00_19['SCORE'] = df00_19['SCORE'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "504a9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df00_19 = df00_19.loc[(df00_19['PLAYER1_NAME'] == 'Tim Duncan') | (df00_19['PLAYER1_NAME'] == 'Kobe Bryant') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Allen Iverson') | (df00_19['PLAYER1_NAME'] == 'Steve Nash') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Ray Allen') | (df00_19['PLAYER1_NAME'] == 'Paul Pierce')\n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Pau Gasol') | (df00_19['PLAYER1_NAME'] == 'Tony Parker') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Manu Ginobili') | (df00_19['PLAYER1_NAME'] == 'Dwyane Wade') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'LeBron James') | (df00_19['PLAYER1_NAME'] == 'Chris Paul')\n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Kevin Durant') | (df00_19['PLAYER1_NAME'] == 'Russell Westbrook') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Stephen Curry') | (df00_19['PLAYER1_NAME'] == 'James Harden') \n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Kawhi Leonard') | (df00_19['PLAYER1_NAME'] == 'Damian Lillard')\n",
    "                    | (df00_19['PLAYER1_NAME'] == 'Anthony Davis') | (df00_19['PLAYER1_NAME'] == 'Giannis Antetokounmpo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9e1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renommer les colonnes pour pouvoir fusionner avec le df1\n",
    "df00_19 = df00_19.rename({'GAME_ID' : 'Game ID', 'PCTIMESTRING' : 'Tps_restant', 'PERIOD' : 'Period', 'EVENTNUM' : 'Game Event ID'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f30b61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer les RAS de HOMEDESCRIPTION ET VISITDESCRIPTION par RAS\n",
    "\n",
    "df00_19['HOMEDESCRIPTION'] = df00_19['HOMEDESCRIPTION'].fillna('RAS')\n",
    "df00_19['VISITORDESCRIPTION'] = df00_19['VISITORDESCRIPTION'].fillna('RAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb5b7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusionner le df1 avec le df00_19\n",
    "\n",
    "df00_19['Game Event ID'] = df00_19['Game Event ID'].apply(int)\n",
    "df00_19['Period'] = df00_19['Period'].apply(int)\n",
    "df00_19['Game ID'] = df00_19['Game ID'].apply(int)\n",
    "df00_19 = df00_19.drop_duplicates(subset = ['Game Event ID','Game ID','Tps_restant'],keep = 'last')\n",
    "\n",
    "df = df1.merge(right = df00_19, on = ['Period','Game ID','Game Event ID','Tps_restant'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b2daf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la variable \"mène\" en fonction du score\n",
    "# 1 : mène, 0 : égalité, -1 : mené\n",
    "\n",
    "df['SCOREMARGIN'] = df['SCOREMARGIN'].apply(int)\n",
    "\n",
    "df['mène'] = np.where((df['domicile'] == 1) & (df['SCOREMARGIN'] < 0),-1,\n",
    "             np.where((df['domicile'] == 1) & (df['SCOREMARGIN'] > 0),1,\n",
    "             np.where((df['domicile'] == 0) & (df['SCOREMARGIN'] > 0),-1,\n",
    "             np.where((df['domicile'] == 0) & (df['SCOREMARGIN'] < 0),1,\n",
    "            ''))))\n",
    "                                                                                  \n",
    "df['mène'] = np.where(df['SCOREMARGIN'] == 0,0,df['mène'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aeae0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affinage du dataset, certaines variables nécessaires à la dataviz sont conservées à ce stade\n",
    "df = df.drop([\"Game ID\",\"Game Event ID\",\"Player ID\", \"Team ID\",\"Team Name\", \"Game Date\",\"birth_date\", \"year_birth_date\",\"month_birth_date\",\n",
    "              \"day_birth_date\", \"date_birth_date\", \"month_Game Date\",\"day_Game Date\", \"date_Game Date\",\n",
    "              \"SEASON\", \"CONFERENCE_ADVERSAIRE\",  \"Home Team\",\"Away Team\",\n",
    "              \"Season Type\",\"TEAM_ABBREVIATION\",\"adversaire\", \"EVENTMSGTYPE\",\n",
    "              \"HOMEDESCRIPTION\", \"PLAYER1_ID\",\"PLAYER1_NAME\",\"PLAYER1_TEAM_ABBREVIATION\",\"PLAYER1_TEAM_ID\",\n",
    "              \"PLAYER2_NAME\", \"PLAYER3_NAME\",\"SCORE\",\"VISITORDESCRIPTION\",\"VISITOR_TEAM_ID\",\"HOME_TEAM_ID\",\"adversaire_ID\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89474420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de string à int pour 'position'\n",
    "# Meneur de jeu (1)\n",
    "df.loc[(df['Player Name'].str.contains(\"Parker\")) | \n",
    "       (df['Player Name'].str.contains(\"Nash\")) | \n",
    "       (df['Player Name'].str.contains(\"Paul\")) | \n",
    "       (df['Player Name'].str.contains(\"Curry\")) | \n",
    "       (df['Player Name'].str.contains(\"Lillard\")) |\n",
    "       (df['Player Name'].str.contains(\"Westbrook\")) ,'position'] = 1 \n",
    "# Arrière (2)\n",
    "df.loc[(df['Player Name'].str.contains(\"Ginobili\")) |\n",
    "       (df['Player Name'].str.contains(\"Bryant\")) |\n",
    "       (df['Player Name'].str.contains(\"Wade\")) |\n",
    "       df['Player Name'].str.contains(\"Pierce\") | df['Player Name'].str.contains(\"Allen\") |\n",
    "       df['Player Name'].str.contains(\"Harden\"),'position'] = 2\n",
    "# Ailier shooteur (3)\n",
    "df.loc[(df['Player Name'].str.contains(\"Kawhi\")) | \n",
    "       (df['Player Name'].str.contains(\"LeBron\")) | \n",
    "       (df['Player Name'].str.contains(\"Durant\")),'position'] = 3  \n",
    "# Ailier fort (4)\n",
    "df.loc[(df['Player Name'].str.contains(\"Duncan\")) |\n",
    "       (df['Player Name'].str.contains(\"Davis\")) |\n",
    "       (df['Player Name'].str.contains(\"Giannis\")) ,'position'] = 4\n",
    "# Pivot (5)\n",
    "df.loc[df['Player Name'].str.contains(\"Gasol\"),'position'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a234caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION DISTANCE DE FOOT A METRES\n",
    "df['Shot Distance'] = df['Shot Distance']*0.3048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5770b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renommage des colonnes pour harmoniser\n",
    "df.rename(columns={\n",
    "\"Period\":  \"period\" ,\n",
    "\"Minutes Remaining\": \"minutes_remaining\",\n",
    "\"Seconds Remaining\": \"seconds_remaining\",\n",
    "\"Action Type\":\"action_type\" , \n",
    "\"Shot Type\":\"shot_type\",\n",
    "\"Shot Distance\": \"shot_distance\",\n",
    "\"Shot Made Flag\": \"shot_made_flag\" ,\n",
    "\"W_PCT\":\"w_pct_adverse\",\n",
    "\"classement\" : \"classement_adversaire\",\n",
    "\"SCOREMARGIN\":\"score_margin\",\n",
    "\"Shot Zone Basic\": \"shot_zone_basic\",\n",
    "\"Shot Zone Area\": \"shot_zone_area\",\n",
    "\"Shot Zone Range\": \"shot_zone_range\",\n",
    "\"Tps_restant\": \"temps_restant\",\n",
    "\"Player Name\": \"player_name\",\n",
    "\"X Location\": \"x_location\",\n",
    "\"Y Location\": \"y_location\",\n",
    "\"year_Game Date\": \"year_game_date\"\n",
    "}, inplace=True)\n",
    "df['year_game_date'] = df['year_game_date'].astype(int)\n",
    "#20 variables, 40.8+ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e93baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une colonne unique en secondes pour le temps restant\n",
    "df[\"temps_restant\"] = (df[\"minutes_remaining\"]*60) + (df[\"seconds_remaining\"])\n",
    "df = df.drop([\"minutes_remaining\",\"seconds_remaining\"],axis = 1)\n",
    "df['temps_restant'] = df['temps_restant'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd2f7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shot_type'] = df['shot_type'].replace(['2PT Field Goal', '3PT Field Goal'], [2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d99db6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la mémoire qu'occupe le Dataset\n",
    "df[\"period\"] = df[\"period\"].astype('int8')\n",
    "df['action_type'] = df['action_type'].astype('category')\n",
    "df['shot_distance'] = df['shot_distance'].astype('float32')\n",
    "df['shot_made_flag'] = df['shot_made_flag'].astype('int8')\n",
    "df['position'] = df['position'].astype('int8')\n",
    "df['age'] = df['age'].astype('int8')\n",
    "df['w_pct_adverse'] = df['w_pct_adverse'].astype('float32')\n",
    "df['domicile'] = df['domicile'].astype('int8')\n",
    "df['angle_tir'] = df['angle_tir'].astype('float32')\n",
    "df['score_margin'] = df['score_margin'].astype('int8')\n",
    "df['mène'] = df['mène'].astype('int8')\n",
    "\n",
    "df.to_pickle('Nettoyage_données_NBA_DataViz.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6672c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shot_distance'] = np.round(df['shot_distance'],2)\n",
    "df['angle_tir'] = np.round(df['angle_tir'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1e9ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"shot_zone_basic\",\"shot_zone_area\", \"shot_zone_range\",\"player_name\",\n",
    "             \"x_location\", \"y_location\",\"year_game_date\",\"classement_adversaire\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c900398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('Nettoyage_données_NBA.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
